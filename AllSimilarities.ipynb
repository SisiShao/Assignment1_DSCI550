{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "\r\n",
                "from tika import parser\r\n",
                "import os, editdistance, itertools, argparse, csv\r\n",
                "from requests import ConnectionError\r\n",
                "from time import sleep\r\n",
                "import ast\r\n",
                "import pandas as pd\r\n",
                "import json\r\n",
                "from functools import reduce"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "\r\n",
                "import math\r\n",
                "\r\n",
                "def stringify(attribute_value):\r\n",
                "    if isinstance(attribute_value, list):\r\n",
                "        return str((\", \".join(attribute_value)).strip())\r\n",
                "    else:\r\n",
                "        return str(attribute_value.strip())\r\n",
                "\r\n",
                "\r\n",
                "class Vector:\r\n",
                "    '''\r\n",
                "    An instance of this class represents a vector in n-dimensional space\r\n",
                "    '''\r\n",
                "    \r\n",
                "    def __init__(self, filename=None, features=None, config_params=None):\r\n",
                "        '''\r\n",
                "        Create a vector\r\n",
                "        @param metadata features \r\n",
                "        '''\r\n",
                "        self.features = {}\r\n",
                "        \r\n",
                "        if filename and features:\r\n",
                "            self.filename = filename #filename is basically id for the vector\r\n",
                "\r\n",
                "            if(config_params):\r\n",
                "                for key in config_params:\r\n",
                "                    if(key in features):\r\n",
                "                        if config_params[key] == \"string\":\r\n",
                "                            self.features[key] = hash(stringify(features[key]))\r\n",
                "                        elif config_params[key] == \"int\":\r\n",
                "                            self.features[key] = int(features[key])\r\n",
                "                        elif config_params[key] == \"double\":\r\n",
                "                            # print(key+\" \"+features[key])\r\n",
                "                            self.features[key] = float(features[key])\r\n",
                "                        elif config_params[key] == \"date\":\r\n",
                "                            try:\r\n",
                "                                self.features[key] = int(d.strptime(features[key],\"%Y-%m-%d\").strftime('%s'))\r\n",
                "                            except:\r\n",
                "                                self.features[key] = int(features[key])\r\n",
                "            else:\r\n",
                "                na_metadata = [\"resourceName\"]\r\n",
                "\r\n",
                "                for na in na_metadata:\r\n",
                "                    features.pop(na, None)\r\n",
                "\r\n",
                "                for key,value in features.items():\r\n",
                "                    self.features[key] = len(stringify(value))\r\n",
                "\r\n",
                "\r\n",
                "    '''\r\n",
                "    def __str__(self):        \r\n",
                "        vector_str = \"( {0} ): \\n\".format(self.)\r\n",
                "        if self.features:\r\n",
                "            for key in self.features:\r\n",
                "                vector_str += \" {1}: {2} \\n\".format(key, self.features[key])\r\n",
                "        return vector_str+\"\\n\"\r\n",
                "    '''\r\n",
                "\r\n",
                "    def getMagnitude(self):\r\n",
                "        totalMagnitude = 0.0\r\n",
                "        for key in self.features:\r\n",
                "            totalMagnitude += self.features[key] ** 2\r\n",
                "        return math.sqrt(totalMagnitude)\r\n",
                "\r\n",
                "\r\n",
                "    def dotProduct(self, anotherVector):\r\n",
                "        '''\r\n",
                "        A = ax+by+cz\r\n",
                "        B = mx+ny+oz\r\n",
                "        A.B = a*m + b*n + c*o\r\n",
                "        '''        \r\n",
                "        dot_product = 0.0\r\n",
                "        intersect_features = set(self.features) & set(anotherVector.features)\r\n",
                "        \r\n",
                "        for feature in intersect_features:\r\n",
                "            dot_product += self.features[feature] * anotherVector.features[feature]\r\n",
                "        return dot_product\r\n",
                "\r\n",
                "\r\n",
                "    def cosTheta(self, v2):\r\n",
                "        '''\r\n",
                "        cosTheta = (V1.V2) / (|V1| |V2|)\r\n",
                "        cos 0 = 1 implies identical documents\r\n",
                "        '''\r\n",
                "        return self.dotProduct(v2) / (self.getMagnitude() * v2.getMagnitude())\r\n",
                "\r\n",
                "\r\n",
                "    def euclidean_dist(self, anotherVector):\r\n",
                "        '''\r\n",
                "        dist = ((x1-x2)^2 + (y1-y2)^2 + (z1-z2)^2)^(0.5)\r\n",
                "        '''\r\n",
                "        intersect_features = set(self.features) & set(anotherVector.features)\r\n",
                "\r\n",
                "        dist_sum = 0.0\r\n",
                "        for feature in intersect_features:\r\n",
                "            dist_sum += (self.features[feature] - anotherVector.features[feature]) ** 2\r\n",
                "\r\n",
                "        setA = set(self.features) - intersect_features\r\n",
                "        for feature in setA:\r\n",
                "            dist_sum += self.features[feature] ** 2\r\n",
                "\r\n",
                "        setB = set(anotherVector.features) - intersect_features\r\n",
                "        for feature in setB:\r\n",
                "            dist_sum += anotherVector.features[feature] ** 2\r\n",
                "\r\n",
                "        return math.sqrt(dist_sum)\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "inputDir = 'SisiHTML/'\r\n",
                "na_metadata = [\"resourceName\"]\r\n",
                "filename_list = []\r\n",
                "\r\n",
                "for root,_, files in os.walk(inputDir):\r\n",
                "    for filename in files:\r\n",
                "        filename_list.append(filename)\r\n",
                "\r\n",
                "All_features = {}\r\n",
                "for filename in filename_list:\r\n",
                "    All_features[filename] = parser.from_file(inputDir + filename)[\"metadata\"]\r\n",
                "\r\n",
                "data_cosine = []\r\n",
                "data_jaccard = []\r\n",
                "data_edit = []\r\n",
                "files_tuple = itertools.combinations(filename_list, 2)\r\n",
                "for file1, file2 in files_tuple:\r\n",
                "    features = All_features[file1]\r\n",
                "    features2 = All_features[file2]\r\n",
                "\r\n",
                "\r\n",
                "    # Cosine ******************************************************************************************\r\n",
                "    try:\r\n",
                "        v1 = Vector(file1, features)\r\n",
                "        v2 = Vector(file2, features2)\r\n",
                "        data_cosine.append([file1, file2, v1.cosTheta(v2)])\r\n",
                "    except:\r\n",
                "        pass\r\n",
                "\r\n",
                "    # Jaccard ******************************************************************************************\r\n",
                "    try:\r\n",
                "        f1MetaData = features\r\n",
                "        f2MetaData = features2\r\n",
                "        isCoExistant = lambda k: ( k in f2MetaData) and ( f1MetaData[k] == f2MetaData[k] )\r\n",
                "        intersection = reduce(lambda m,k: (m + 1) if isCoExistant(k) else m, list(f1MetaData.keys()), 0)\r\n",
                "        union = len(list(f1MetaData.keys())) + len(list(f2MetaData.keys())) - intersection\r\n",
                "        jaccard = float(intersection) / union\r\n",
                "        data_jaccard.append([file1, file2, jaccard])\r\n",
                "    except:\r\n",
                "        pass\r\n",
                "\r\n",
                "    # Edit   ******************************************************************************************\r\n",
                "    try:\r\n",
                "        file1_parsedData = features\r\n",
                "        file2_parsedData = features2\r\n",
                "        intersect_features = set(file1_parsedData.keys()) & set(file2_parsedData.keys()) \r\n",
                "        intersect_features = [feature for feature in intersect_features if feature not in na_metadata ]\r\n",
                "        file_edit_distance = 0.0\r\n",
                "        for feature in intersect_features:\r\n",
                "            file1_feature_value = stringify(file1_parsedData[feature])\r\n",
                "            file2_feature_value = stringify(file2_parsedData[feature])\r\n",
                "            if len(file1_feature_value) == 0 and len(file2_feature_value) == 0:\r\n",
                "                feature_distance = 0.0\r\n",
                "            else:\r\n",
                "                feature_distance = float(editdistance.eval(file1_feature_value, file2_feature_value))/(len(file1_feature_value) if len(file1_feature_value) > len(file2_feature_value) else len(file2_feature_value))\r\n",
                "            file_edit_distance += feature_distance\r\n",
                "        if allKeys:\r\n",
                "            file1_only_features = set(file1_parsedData.keys()) - set(intersect_features)\r\n",
                "            file1_only_features = [feature for feature in file1_only_features if feature not in na_metadata]\r\n",
                "\r\n",
                "            file2_only_features = set(file2_parsedData.keys()) - set(intersect_features)\r\n",
                "            file2_only_features = [feature for feature in file2_only_features if feature not in na_metadata]\r\n",
                "\r\n",
                "            file_edit_distance += len(file1_only_features) + len(file2_only_features)       # increment by 1 for each disjunct feature in (A-B) & (B-A), file1_disjunct_feature_value/file1_disjunct_feature_value = 1\r\n",
                "            file_edit_distance /= float(len(intersect_features) + len(file1_only_features) + len(file2_only_features))\r\n",
                "\r\n",
                "        else:\r\n",
                "            file_edit_distance /= float(len(intersect_features))    #average edit distance\r\n",
                "        data_edit.append([file1, file2, 1-file_edit_distance])\r\n",
                "    except:\r\n",
                "        pass\r\n",
                "\r\n",
                "df_cosine = pd.DataFrame(data=data_cosine,columns=[\"x-coordinate\",\"y-coordinate\",\"Similarity_score\"])\r\n",
                "df_jaccard = pd.DataFrame(data=data_jaccard,columns=[\"x-coordinate\",\"y-coordinate\",\"Similarity_score\"])\r\n",
                "df_edit = pd.DataFrame(data=data_edit,columns=[\"x-coordinate\",\"y-coordinate\",\"Similarity_score\"])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "df_cosine.to_csv('cosine_similarity.csv',index=False)\r\n",
                "df_jaccard.to_csv('jaccard_similarity.csv',index=False)\r\n",
                "df_edit.to_csv('edit_similarity.csv',index=False)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.3 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}